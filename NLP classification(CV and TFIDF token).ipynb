{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a1bf9d-bbb6-48a1-8eb9-4537c8c90c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NLP Text Calssification Model using Counter Vector(CV) and Term Frequency-Inverse Document Frequency(TF-)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3812b5d1-a95f-4b81-80b0-c8892b42fbda",
   "metadata": {},
   "source": [
    "#### Create a bag of word model from spam dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "43236d2b-f02c-402b-bc8f-bdfd18158d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "spam_df = pd.read_csv('data/spam.csv', usecols=['v1', 'v2'], encoding='latin1')\n",
    "spam_df.rename(columns={'v1': 'Label', 'v2': 'Message'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e17839cf-3d95-45c4-bc33-6f231325fcfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                            Message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4783e07d-8114-4b8b-a24a-99c4289e9086",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Uthanda\n",
      "[nltk_data]     Ramu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bce13087-fc34-4a2c-a951-d685069a2885",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d87de168-0acb-4add-877f-c0f349a82e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for i in range(len(spam_df)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', spam_df[\"Message\"][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = \" \".join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e5c99c-7d6a-4a7b-8a1b-c92cad830746",
   "metadata": {},
   "source": [
    "#### Using CounterVectorizer and TfidfVectorizer for tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "14639e23-b2a4-49e8-b9bc-42a67706ff1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "cv = CountVectorizer(max_features=2500, ngram_range=(1,2))\n",
    "tfidf = TfidfVectorizer(max_features=2500, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "30c815c1-2b1e-45e7-8043-7d75b2ab0951",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cv = cv.fit_transform(corpus).toarray()\n",
    "x_tfidf = tfidf.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1b4c7c69-2770-403d-8669-3dc0f31141c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(spam_df['Label'])\n",
    "y = y.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5bab8632-4084-4aac-9071-b9bc4a02997d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572,)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7207c4be-0534-41c7-a2db-6963ad1daad4",
   "metadata": {},
   "source": [
    "#### Using CounterVectorizer and TfidfVectorizer tokens for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "26069e42-d2b3-49d8-8702-23db9ae9bb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train_cv, x_test_cv, y_train_cv, y_test_cv = train_test_split(x_cv, y, test_size=0.2, random_state=21)\n",
    "x_train_tfidf, x_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(x_tfidf, y, test_size=0.2, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e7c6d2cb-be8d-4ee9-91b6-5c44b7c498ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "spam_detect_model_cv = MultinomialNB().fit(x_train_cv, y_train_cv)\n",
    "spam_detect_model_tfidf = MultinomialNB().fit(x_train_tfidf, y_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bbdecc0b-03fa-4d3e-b759-3aa342ab0795",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction\n",
    "y_pred_cv = spam_detect_model_cv.predict(x_test_cv)\n",
    "y_pred_tfidf = spam_detect_model_tfidf.predict(x_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "38008784-9cbb-4591-ab19-a1f13735f598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9847533632286996\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.94      0.94       140\n",
      "        True       0.99      0.99      0.99       975\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.96      0.97      0.97      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Metrics evaluation on cv tokens\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "print(accuracy_score(y_test_cv, y_pred_cv))\n",
    "print(classification_report(y_test_cv, y_pred_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5c2389e5-88f0-413d-938a-a7fe1a45c4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9802690582959641\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.85      0.91       136\n",
      "        True       0.98      1.00      0.99       979\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.99      0.92      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Metrics evaluation on tfidf tokens\n",
    "print(accuracy_score(y_test_tfidf, y_pred_tfidf))\n",
    "print(classification_report(y_test_tfidf, y_pred_tfidf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
